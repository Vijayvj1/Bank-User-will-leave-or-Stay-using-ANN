{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":5,"outputs":[{"output_type":"stream","text":"/kaggle/input/Churn_Modelling.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Artificial Neural Network\n\n# Installing Theano\n# pip install --upgrade --no-deps git+git://github.com/Theano/Theano.git\n\n# Installing Tensorflow\n# pip install tensorflow\n\n# Installing Keras\n# pip install --upgrade keras\n\n# Part 1 - Data Preprocessing\n\n# Importing the libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Importing the dataset\ndataset = pd.read_csv('/kaggle/input/Churn_Modelling.csv')\nX = dataset.iloc[:, 3:13].values\ny = dataset.iloc[:, 13].values\n\n# Encoding categorical data\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\n# Male/Female\nlabelencoder_X_1 = LabelEncoder()\nX[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\nlabelencoder_X_2 = LabelEncoder()\nX[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n\n# Country column\nct = ColumnTransformer([(\"Country\", OneHotEncoder(), [1])], remainder = 'passthrough')\nX = ct.fit_transform(X)\n\n\n\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\n# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\n# Part 2 - Now let's make the ANN!\n\n# Importing the Keras libraries and packages\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n# Initialising the ANN\nclassifier = Sequential()\n\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 12))\n\n# Adding the second hidden layer\nclassifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n\n# Adding the output layer\nclassifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n\n# Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n# Fitting the ANN to the Training set\nclassifier.fit(X_train, y_train, batch_size = 10, epochs = 100)\n\n# Part 3 - Making predictions and evaluating the model\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)\ny_pred = (y_pred > 0.5)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)","execution_count":11,"outputs":[{"output_type":"stream","text":"Epoch 1/100\n8000/8000 [==============================] - 1s 163us/step - loss: 0.4877 - accuracy: 0.7959\nEpoch 2/100\n8000/8000 [==============================] - 1s 121us/step - loss: 0.4300 - accuracy: 0.7960\nEpoch 3/100\n8000/8000 [==============================] - 1s 123us/step - loss: 0.4234 - accuracy: 0.7960\nEpoch 4/100\n8000/8000 [==============================] - 1s 123us/step - loss: 0.4190 - accuracy: 0.8146\nEpoch 5/100\n8000/8000 [==============================] - 1s 124us/step - loss: 0.4167 - accuracy: 0.8256\nEpoch 6/100\n8000/8000 [==============================] - 1s 123us/step - loss: 0.4149 - accuracy: 0.8296\nEpoch 7/100\n8000/8000 [==============================] - 1s 128us/step - loss: 0.4128 - accuracy: 0.8305\nEpoch 8/100\n8000/8000 [==============================] - 1s 121us/step - loss: 0.4116 - accuracy: 0.8320\nEpoch 9/100\n8000/8000 [==============================] - 1s 123us/step - loss: 0.4107 - accuracy: 0.8320\nEpoch 10/100\n8000/8000 [==============================] - 1s 123us/step - loss: 0.4095 - accuracy: 0.8321\nEpoch 11/100\n8000/8000 [==============================] - 1s 129us/step - loss: 0.4088 - accuracy: 0.8319\nEpoch 12/100\n8000/8000 [==============================] - 1s 122us/step - loss: 0.4079 - accuracy: 0.8349\nEpoch 13/100\n8000/8000 [==============================] - 1s 124us/step - loss: 0.4070 - accuracy: 0.8342\nEpoch 14/100\n8000/8000 [==============================] - 1s 123us/step - loss: 0.4067 - accuracy: 0.8330\nEpoch 15/100\n8000/8000 [==============================] - 1s 124us/step - loss: 0.4062 - accuracy: 0.8338\nEpoch 16/100\n8000/8000 [==============================] - 1s 124us/step - loss: 0.4055 - accuracy: 0.8338\nEpoch 17/100\n8000/8000 [==============================] - 1s 123us/step - loss: 0.4048 - accuracy: 0.8355\nEpoch 18/100\n8000/8000 [==============================] - 1s 124us/step - loss: 0.4049 - accuracy: 0.8336\nEpoch 19/100\n8000/8000 [==============================] - 1s 123us/step - loss: 0.4043 - accuracy: 0.8341\nEpoch 20/100\n8000/8000 [==============================] - 1s 123us/step - loss: 0.4042 - accuracy: 0.8338\nEpoch 21/100\n8000/8000 [==============================] - 1s 123us/step - loss: 0.4039 - accuracy: 0.8340\nEpoch 22/100\n8000/8000 [==============================] - 1s 127us/step - loss: 0.4036 - accuracy: 0.8336\nEpoch 23/100\n8000/8000 [==============================] - 1s 124us/step - loss: 0.4034 - accuracy: 0.8347\nEpoch 24/100\n8000/8000 [==============================] - 1s 123us/step - loss: 0.4034 - accuracy: 0.8335\nEpoch 25/100\n8000/8000 [==============================] - 1s 125us/step - loss: 0.4028 - accuracy: 0.8326\nEpoch 26/100\n8000/8000 [==============================] - 1s 124us/step - loss: 0.4025 - accuracy: 0.8339\nEpoch 27/100\n8000/8000 [==============================] - 1s 124us/step - loss: 0.4026 - accuracy: 0.8345\nEpoch 28/100\n8000/8000 [==============================] - 1s 124us/step - loss: 0.4028 - accuracy: 0.8329\nEpoch 29/100\n8000/8000 [==============================] - 1s 123us/step - loss: 0.4017 - accuracy: 0.8340\nEpoch 30/100\n8000/8000 [==============================] - 1s 125us/step - loss: 0.4025 - accuracy: 0.8334\nEpoch 31/100\n8000/8000 [==============================] - 1s 124us/step - loss: 0.4025 - accuracy: 0.8347\nEpoch 32/100\n8000/8000 [==============================] - 1s 124us/step - loss: 0.4025 - accuracy: 0.8340\nEpoch 33/100\n8000/8000 [==============================] - 1s 128us/step - loss: 0.4018 - accuracy: 0.8341\nEpoch 34/100\n8000/8000 [==============================] - 1s 128us/step - loss: 0.4020 - accuracy: 0.8342\nEpoch 35/100\n8000/8000 [==============================] - 1s 134us/step - loss: 0.4019 - accuracy: 0.8342\nEpoch 36/100\n8000/8000 [==============================] - 1s 130us/step - loss: 0.4018 - accuracy: 0.8339\nEpoch 37/100\n8000/8000 [==============================] - 1s 123us/step - loss: 0.4019 - accuracy: 0.8340\nEpoch 38/100\n8000/8000 [==============================] - 1s 135us/step - loss: 0.4016 - accuracy: 0.8336\nEpoch 39/100\n8000/8000 [==============================] - 1s 125us/step - loss: 0.4017 - accuracy: 0.8340\nEpoch 40/100\n8000/8000 [==============================] - 1s 136us/step - loss: 0.4012 - accuracy: 0.8342\nEpoch 41/100\n8000/8000 [==============================] - 1s 128us/step - loss: 0.4015 - accuracy: 0.8349\nEpoch 42/100\n8000/8000 [==============================] - 1s 129us/step - loss: 0.4011 - accuracy: 0.8342\nEpoch 43/100\n8000/8000 [==============================] - 1s 127us/step - loss: 0.4011 - accuracy: 0.8356\nEpoch 44/100\n8000/8000 [==============================] - 1s 129us/step - loss: 0.4014 - accuracy: 0.8339\nEpoch 45/100\n8000/8000 [==============================] - 1s 126us/step - loss: 0.4014 - accuracy: 0.8341\nEpoch 46/100\n8000/8000 [==============================] - 1s 126us/step - loss: 0.4012 - accuracy: 0.8347\nEpoch 47/100\n8000/8000 [==============================] - 1s 126us/step - loss: 0.4011 - accuracy: 0.8350\nEpoch 48/100\n8000/8000 [==============================] - 1s 128us/step - loss: 0.4007 - accuracy: 0.8334\nEpoch 49/100\n8000/8000 [==============================] - 1s 125us/step - loss: 0.4012 - accuracy: 0.8347\nEpoch 50/100\n8000/8000 [==============================] - 1s 126us/step - loss: 0.4009 - accuracy: 0.8334\nEpoch 51/100\n8000/8000 [==============================] - 1s 125us/step - loss: 0.4009 - accuracy: 0.8329\nEpoch 52/100\n8000/8000 [==============================] - 1s 126us/step - loss: 0.4007 - accuracy: 0.8334\nEpoch 53/100\n8000/8000 [==============================] - 1s 126us/step - loss: 0.4006 - accuracy: 0.8353\nEpoch 54/100\n8000/8000 [==============================] - 1s 127us/step - loss: 0.4013 - accuracy: 0.8349\nEpoch 55/100\n8000/8000 [==============================] - 1s 128us/step - loss: 0.4010 - accuracy: 0.8320\nEpoch 56/100\n8000/8000 [==============================] - 1s 127us/step - loss: 0.4010 - accuracy: 0.8347\nEpoch 57/100\n8000/8000 [==============================] - 1s 126us/step - loss: 0.4011 - accuracy: 0.8341\nEpoch 58/100\n8000/8000 [==============================] - 1s 124us/step - loss: 0.4007 - accuracy: 0.8324\nEpoch 59/100\n8000/8000 [==============================] - 1s 125us/step - loss: 0.4008 - accuracy: 0.8325\nEpoch 60/100\n8000/8000 [==============================] - 1s 124us/step - loss: 0.4006 - accuracy: 0.8349\nEpoch 61/100\n8000/8000 [==============================] - 1s 127us/step - loss: 0.4006 - accuracy: 0.8329\nEpoch 62/100\n8000/8000 [==============================] - 1s 127us/step - loss: 0.4009 - accuracy: 0.8349\nEpoch 63/100\n8000/8000 [==============================] - 1s 126us/step - loss: 0.4006 - accuracy: 0.8332\nEpoch 64/100\n8000/8000 [==============================] - 1s 126us/step - loss: 0.4007 - accuracy: 0.8344\nEpoch 65/100\n8000/8000 [==============================] - 1s 126us/step - loss: 0.4012 - accuracy: 0.8339\nEpoch 66/100\n8000/8000 [==============================] - 1s 126us/step - loss: 0.4004 - accuracy: 0.8332\nEpoch 67/100\n8000/8000 [==============================] - 1s 126us/step - loss: 0.4008 - accuracy: 0.8339\nEpoch 68/100\n8000/8000 [==============================] - 1s 127us/step - loss: 0.4004 - accuracy: 0.8339\nEpoch 69/100\n8000/8000 [==============================] - 1s 124us/step - loss: 0.4006 - accuracy: 0.8325\nEpoch 70/100\n8000/8000 [==============================] - 1s 125us/step - loss: 0.4009 - accuracy: 0.8335\nEpoch 71/100\n8000/8000 [==============================] - 1s 127us/step - loss: 0.3997 - accuracy: 0.8341\nEpoch 72/100\n8000/8000 [==============================] - 1s 133us/step - loss: 0.4005 - accuracy: 0.8339\nEpoch 73/100\n8000/8000 [==============================] - 1s 126us/step - loss: 0.4005 - accuracy: 0.8347\nEpoch 74/100\n8000/8000 [==============================] - 1s 126us/step - loss: 0.4005 - accuracy: 0.8354\nEpoch 75/100\n8000/8000 [==============================] - 1s 125us/step - loss: 0.4003 - accuracy: 0.8335\nEpoch 76/100\n8000/8000 [==============================] - 1s 129us/step - loss: 0.4003 - accuracy: 0.8370\nEpoch 77/100\n8000/8000 [==============================] - 1s 125us/step - loss: 0.4004 - accuracy: 0.8341\nEpoch 78/100\n","name":"stdout"},{"output_type":"stream","text":"8000/8000 [==============================] - 1s 127us/step - loss: 0.4003 - accuracy: 0.8345\nEpoch 79/100\n8000/8000 [==============================] - 1s 126us/step - loss: 0.4002 - accuracy: 0.8347\nEpoch 80/100\n8000/8000 [==============================] - 1s 127us/step - loss: 0.4002 - accuracy: 0.8347\nEpoch 81/100\n8000/8000 [==============================] - 1s 123us/step - loss: 0.3998 - accuracy: 0.8340\nEpoch 82/100\n8000/8000 [==============================] - 1s 125us/step - loss: 0.4005 - accuracy: 0.8369\nEpoch 83/100\n8000/8000 [==============================] - 1s 125us/step - loss: 0.4002 - accuracy: 0.8349\nEpoch 84/100\n8000/8000 [==============================] - 1s 126us/step - loss: 0.3998 - accuracy: 0.8328\nEpoch 85/100\n8000/8000 [==============================] - 1s 125us/step - loss: 0.3995 - accuracy: 0.8338\nEpoch 86/100\n8000/8000 [==============================] - 1s 124us/step - loss: 0.4000 - accuracy: 0.8347\nEpoch 87/100\n8000/8000 [==============================] - 1s 129us/step - loss: 0.3997 - accuracy: 0.8357\nEpoch 88/100\n8000/8000 [==============================] - 1s 127us/step - loss: 0.4006 - accuracy: 0.8331\nEpoch 89/100\n8000/8000 [==============================] - 1s 126us/step - loss: 0.3996 - accuracy: 0.8345\nEpoch 90/100\n8000/8000 [==============================] - 1s 124us/step - loss: 0.4002 - accuracy: 0.8344\nEpoch 91/100\n8000/8000 [==============================] - 1s 124us/step - loss: 0.4000 - accuracy: 0.8325\nEpoch 92/100\n8000/8000 [==============================] - 1s 125us/step - loss: 0.4000 - accuracy: 0.8356\nEpoch 93/100\n8000/8000 [==============================] - 1s 128us/step - loss: 0.4003 - accuracy: 0.8345\nEpoch 94/100\n8000/8000 [==============================] - 1s 151us/step - loss: 0.3996 - accuracy: 0.8355\nEpoch 95/100\n8000/8000 [==============================] - 1s 138us/step - loss: 0.3995 - accuracy: 0.8355\nEpoch 96/100\n8000/8000 [==============================] - 1s 133us/step - loss: 0.3999 - accuracy: 0.8334\nEpoch 97/100\n8000/8000 [==============================] - 1s 134us/step - loss: 0.3998 - accuracy: 0.8350\nEpoch 98/100\n8000/8000 [==============================] - 1s 136us/step - loss: 0.3996 - accuracy: 0.8340\nEpoch 99/100\n8000/8000 [==============================] - 1s 147us/step - loss: 0.3998 - accuracy: 0.8345\nEpoch 100/100\n8000/8000 [==============================] - 1s 135us/step - loss: 0.3998 - accuracy: 0.8344\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"array([[1543,   52],\n       [ 264,  141]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n\nfrom sklearn.metrics import plot_confusion_matrix","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.heatmap(cm, annot=True)","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"<matplotlib.axes._subplots.AxesSubplot at 0x7f59140e85c0>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}